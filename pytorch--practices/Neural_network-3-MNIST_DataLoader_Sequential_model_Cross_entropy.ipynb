{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwriting dataset loader 이미지쪽은 torchvision ㅇ.ㅇ, denseNet <- best\\ntrain, test dataset을 잘 load할수있게\\ncs231n <-- 강의중 가장 좋음. 딥러닝\\ndata argumentation - 학습할때 이런 테크닉 잘써서. 학습이 잘돼. resize, color 조정 등등,\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "writing dataset loader 이미지쪽은 torchvision ㅇ.ㅇ, denseNet <- best\n",
    "train, test dataset을 잘 load할수있게\n",
    "cs231n <-- 강의중 가장 좋음. 딥러닝\n",
    "data argumentation - 학습할때 이런 테크닉 잘써서. 학습이 잘돼. resize, color 조정 등등,\n",
    "\n",
    "(batch_size, rgb, 28,28)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transform\n",
    "\n",
    "train_dataset = dsets.MNIST(root='../data', train=True, transform=transform.ToTensor(), download=True)\n",
    "\n",
    "\n",
    "\n",
    "for i, (image, label) in enumerate(train_dataset,1):\n",
    "    \n",
    "    if i% 10 == 0:\n",
    "        print(i, image.size())\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f574466f828>\n",
      "Sequential (\n",
      "  (0): Linear (784 -> 100)\n",
      "  (1): ReLU ()\n",
      "  (2): Linear (100 -> 10)\n",
      ")\n",
      "0 0.3162202537059784\n",
      "1 0.1661861687898636\n",
      "2 0.12682849168777466\n",
      "3 0.10697457939386368\n",
      "4 0.09253860265016556\n",
      "5 0.08160346746444702\n",
      "6 0.07163511216640472\n",
      "7 0.06436563283205032\n",
      "8 0.05875277519226074\n",
      "9 0.053861312568187714\n",
      "10 0.04997434839606285\n",
      "11 0.04588191583752632\n",
      "12 0.042449045926332474\n",
      "13 0.03959893807768822\n",
      "14 0.037055060267448425\n",
      "15 0.03490855544805527\n",
      "16 0.033013179898262024\n",
      "17 0.031185509636998177\n",
      "18 0.02963152527809143\n",
      "19 0.028253749012947083\n",
      "20 0.026903675869107246\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e431a2f834ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moutput_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py35/lib/python3.5/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transform\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "train_dataset = dsets.MNIST(root='../data', train=True, transform=transform.ToTensor(), download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(train_loader)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784,100), \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,10))\n",
    "\n",
    "print(model)\n",
    "#loss = nn.MSELoss()\n",
    "loss =nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer는 파라미터 업데이트를 자동으로해줌.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for j in range(100):\n",
    "\n",
    "    for i, (img,label) in enumerate(train_loader):\n",
    "\n",
    "        x = img.view(img.size(0),-1)\n",
    "        x=Variable(x, requires_grad=False)\n",
    "        label=Variable(label, requires_grad=False)\n",
    "        \n",
    "        o = model(x)\n",
    "        output_loss = loss(o,label)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        output_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(j,output_loss.data[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Data set을 구현해야한다.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
